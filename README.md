
<div align="center">
  <img width="187" src="https://user-images.githubusercontent.com/93570324/234292265-889228a8-7a68-4e2d-b891-f75262410af1.png"/>
</div>

<p align="center">
    <b>The AI-native database built for the next-gen Retrieval-Augmented Generation</b>
</p>
---
<h4 align="center">
  <a href="https://www.example.com">Website</a> |
  <a href="https://www.example.com">GitHub Discussions</a> |
  <a href="https://www.youtube.com/@InfiniFlow-AI">YouTube</a> |
  <a href="https://www.meilisearch.com/pricing?utm_campaign=oss&utm_source=github&utm_medium=meilisearch&utm_content=nav">Roadmap 2024</a> |
  <a href="https://twitter.com/infiniflowai">Twitter</a> |
  <a href="https://github.com/infiniflow/infinity/blob/main/LICENSE">Apache 2.0</a> |
  <a href="https://discord.gg/6Zex37FE">Discord</a> |
</h4>


Infinity is an open-source AI-native database designed to enhance retrieval-augmented generation (RAG) applications. As a natural partner to mainstream LLMs, Infinity solves primary challenges faced by B2B applications, such as internal enterprise search, industry-specific search, in-house AI assistants, chatbots, in-house knowledge management systems, and more.

Infinity empowers these applications by supporting full-text search, multi-embedding search, multiple-collection query, and fused search. 

Infinity was released under the [open-source Apache License 2.0](https://github.com/infiniflow/infinity/blob/master/LICENSE) on December 21, 2023.

### Clients

- [Python client]()

### B2B Applications

- In-house enterprise-level search
- specific industry search (domain-specific search?)
- In-house AI assistants
- Chatbots: Combining foundation models to provide more accurate answers
- In-house knowledge management system (ask questions on your own data): See our open-source project [here]()


## Get Started

CONTENT MISSING HERE

## Build from Source

See [Build from Source](build_from_source.md).



## Key Features

Infinity comes with **flexibility**, **performance**, **ease-of-use**, and many features designed to address the challenges facing the next-gen RAG applications:

### Mixed data type query

In addition to embeddings generated by LLMs, Infinity also stores structured and semi-structured data, offering support for mixed data type queries.

### Multi-collection query

Mainstream vector databases in the market only supports queries on one collection.

### Multi-embedding query

### KNN-based fused search on full text

In addition to hybrid search, Infinity takes over the decision-making process previously owned by the upper-level applications, thereby simplifying complex queries considerably.

### Sub-millisecond search on trillion vector datasets

End-to-end latency measured in less than a millisecond on trillion vector datasets. See the [Benchmarking](https://www.example.com).

### Unified, intuitive APIs

We carefully weighed the pros and cons of similar APIs in the market and designed our own.

## Roadmap

- [Infinity Roadmap 2024]()


## Extensive Reading: Frequently Asked Questions

<details>
  <summary><b>What is Retrieval-Augmented Generation?</b></summary>
<p>Retrieval Augmented Generation (RAG) is a technique used to improve the accuracy and reliability of responses from foundation models, specifically Large Language Models (LLMs). It works by supplementing the existing LLMs with external sources of knowledge.</p>
<p>The benefits of using RAG include enhanced response quality and relevance, access to the most current and reliable facts, and the ability to verify the model's responses. It reduces the need for continuous training and updating of the LLM, thereby lowering costs. RAG relies on the use of vectors, which are mathematical representations of data, to enrich prompts with relevant external information.</p>
<p>RAG enables the retrieval of external data from a variety of sources, including document repositories, databases, and APIs. This data is then converted into a compatible format to facilitate relevancy searches. The retrieved information is added to the original user prompt, empowering the LLM to provide responses based on more relevant or up-to-date knowledge.</p>
</details>
<details>
    <summary><b>How do you define a <i>fused search</i>? What's the difference between hybrid search and fused search?</b></summary>
  <p>Hybrid search combines text and semantic (vector) queries to find more accurate and relevant results. This technique combines multiple search algorithms, such as keyword search, natural language search, and semantic search, to enhance the accuracy of search results. </p>
  <p>A hybrid search combines various search strategies, whilst a fused search goes a step further by taking over the decision-making process previously managed by the upper-level application. It merges the obtained results and returns the top K by itself.</p>
  </details>
<details>
  <summary><b>What is an AI-native database? Is it just a paraphrase of vector database?</b></summary>
<p>An AI-native database is designed specifically to address the challenges of retrieval-augmented generation (RAG), which is currently an industry standard for enhancing the accuracy and relevance of responses generated by foundation models. </p>
<p>In addition to basic vector search, an AI-vector database also offers advanced capabilities such as more full-text search, multi-vector retrieval, mixed data type query, refined data analytics, and fused search.</p>
  </details>
<details>
  <summary><b>Where can I find a benchmark report of your database?</b></summary>
 You can find a benchmark report on Infinity, the AI-native database, [here]().
  </details>

## Community

- [Slack](https://join.slack.com/t/infiniflowai/shared_invite/zt-28bstxmrq-WBW7_oyDqct~s8gnYe_6ug)
- [Discord](https://discord.gg/6Zex37FE)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/infiniflow/infinity/discussions)
- WeChat?

<br />

## Contributing

To find out how to make a contribution to Infinity, see the [contribution guidelines](CONTRIBUTING.md).
