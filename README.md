
<div align="center">
  <img width="187" src="https://user-images.githubusercontent.com/93570324/234292265-889228a8-7a68-4e2d-b891-f75262410af1.png"/>
</div>

<p align="center">
    <b>The AI-native database built for the next-gen Retrieval-Augmented Generation</b>
</p>
---

<p align="center">
  <a href="https://discord.gg/6Zex37FE"><b>ðŸ’¬ Discord</b></a> 
</p>



## What is Infinity

Infinity is an open-source AI-native database designed to enhance retrieval-augmented generation (RAG) applications. As a natural partner to mainstream LLMs, Infinity solves primary challenges faced by B2B applications, such as internal enterprise search, industry-specific search, in-house AI assistants, chatbots, in-house knowledge management systems, and more.

Infinity empowers these applications by supporting full-text search, multi-embedding search, multiple-collection query, and fused search. 

Infinity was released under the [open-source Apache License 2.0](https://github.com/infiniflow/infinity/blob/master/LICENSE) on December 21, 2023.

<div align="center"><b>Specifications</b></div>

| Category     | Description                                                  |
| ------------ | ------------------------------------------------------------ |
| Data type    | <li>embeddings generated by mainstream LLMs</li><li>Structured data</li><li>Semi-structured data</li> |
| Index        | <li>`Flat`</li><li>`HNSW`</li>                               |
| LLM          | <li>OpenAI</li><li>Auto-GPT</li>                             |
| OS           | <li>Ubuntu 22.4</li><li>openSUSE Tumbleweed 20230828</li>    |
| Installation | [Docker]() vs. [Build from source]()                         |
| Client       | [Python]()                                                   |
| QPS          | 3,600                                                        |

<div align="center"><b>B2B Applications</b></div>


- In-house enterprise-level search
- specific industry search (domain-specific search?)
- In-house AI assistants
- Chatbots: Combining foundation models to provide more accurate answers
- In-house knowledge management system (ask questions on your own data): See our open-source project [here]()

<div align="center"><b>Architecture</b></div>

**A DIAGRAM IS MISSING HERE.**

## Demos

CONTENT MISSING HERE!

## Target Users

- **Software Engineers** - Who develop applications based on LLM.

- **Data Scientists** - Who use Infinity as fast, flexible AI-native database

- **Data Engineers** - Who use Infinity for a seamless handover of their Machine Learning models to MLOps.

## Why Infinity?

Infinity comes with **flexibility**, **performance**, **ease-of-use**, and many features designed to address the challenges facing the next-gen RAG applications:

<details>
  <summary><b>Mixed data type query</b></summary>
  In addition to embeddings generated by LLMs, Infinity also stores structured and semi-structured data, offering support for mixed data type queries.
  </details>

<details>
  <summary><b>Multi-collection query</b></summary>
  Mainstream vector databases in the market only supports queries on one collection.
  </details>

<details>
  <summary><b>Multi-embedding query</b></summary>
  Mainstream vector databases in the market only supports queries on one collection.
  </details>

<details>
  <summary><b>KNN-based fused search on full text</b></summary>
  In addition to hybrid search, Infinity takes over the decision-making process previously owned by the upper-level applications, thereby simplifying complex queries considerably. 
  </details>

<details>
  <summary><b>Sub-millisecond search on trillion vector datasets</b></summary>
  End-to-end latency measured in less than a millisecond on trillion vector datasets.
  </details>

<details>
  <summary><b>Unified, intuitive APIs</b></summary>
  We carefully weighed the pros and cons of similar APIs in the market and designed our own.
  </details>
<div align="right">

[Benchmarking](https://www.example.com)

</div>

## Docker Installation

CONTENT MISSING HERE

## Build from Source

### Prerequisites
-  Operating system: Ubuntu 22.04,  openSUSE Tumbleweed 20230828 or higher
-  GCC 13 / Clang-18 or higher to support C++23
-  CMake 3.10 or higher

### Step1 Download source code

```shell
$ git clone https://github.com/infiniflow/infinity.git
```

### Step2 Install dependencies

On Ubuntu 22.4+

```shell
# Clang 17 or 18 is required. GCC is not supported.
$ apt install clang-*-17
$ ln -s /usr/lib/llvm-17/bin/clang-scan-deps /usr/bin/clang-scan-deps

# CMake 3.28+ is requrired.
$ wget https://github.com/Kitware/CMake/releases/download/v3.28.0-rc5/cmake-3.28.0-rc5-linux-x86_64.tar.gz
$ tar xzvf cmake-3.28.0-rc5-linux-x86_64.tar.gz
$ sudo cp -r cmake-3.28.0-rc5-linux-x86_64/bin/* /usr/local/bin/

$ sudo apt install make libevent-dev ninja-build bison flex libomp-17-dev libblas-dev liblapack-dev libboost1.81-dev liburing-dev libgflags-dev libleveldb-dev

# iresearch requires lz4
$ git clone https://github.com/lz4/lz4.git
$ cd lz4
$ make
$ sudo make install
$ export LZ4_ROOT=/usr/local

```

### Step3 Build source code

```shell
$ git config --global --add safe.directory infinity
$ cd infinity && mkdir build && cd build
$ export CC=/usr/bin/clang-18
$ export CXX=/usr/bin/clang++-18
$ cmake -G Ninja ..
$ ninja -j 12
```

### Step4 Start up Infinity server

```shell
$ ./src/infinity_main
```

## SDK develop

### Generate thrift rpc code

```shell
$ apt install thrift-compiler 
$ cd tools && python generate_rpc_code.py
```

## Hello, World

CONTENT MISSING HERE



## Roadmap

- [Infinity Roadmap 2024]()


## Extensive Reading: Frequently Asked Questions

<details>
  <summary><b>What is Retrieval-Augmented Generation?</b></summary>
<p>Retrieval Augmented Generation (RAG) is a technique used to improve the accuracy and reliability of responses from foundation models, specifically Large Language Models (LLMs). It works by supplementing the existing LLMs with external sources of knowledge.</p>
<p>The benefits of using RAG include enhanced response quality and relevance, access to the most current and reliable facts, and the ability to verify the model's responses. It reduces the need for continuous training and updating of the LLM, thereby lowering costs. RAG relies on the use of vectors, which are mathematical representations of data, to enrich prompts with relevant external information.</p>
<p>RAG enables the retrieval of external data from a variety of sources, including document repositories, databases, and APIs. This data is then converted into a compatible format to facilitate relevancy searches. The retrieved information is added to the original user prompt, empowering the LLM to provide responses based on more relevant or up-to-date knowledge.</p>
</details>
<details>
    <summary><b>How do you define a <i>fused search</i>? What's the difference between hybrid search and fused search?</b></summary>
  <p>Hybrid search combines text and semantic (vector) queries to find more accurate and relevant results. This technique combines multiple search algorithms, such as keyword search, natural language search, and semantic search, to enhance the accuracy of search results. </p>
  <p>A hybrid search combines various search strategies, whilst a fused search goes a step further by taking over the decision-making process previously managed by the upper-level application. It merges the obtained results and returns the top K by itself.</p>
  </details>
<details>
  <summary><b>What is an AI-native database? Is it just a paraphrase of vector database?</b></summary>
<p>An AI-native database is designed specifically to address the challenges of retrieval-augmented generation (RAG), which is currently an industry standard for enhancing the accuracy and relevance of responses generated by foundation models. </p>
<p>In addition to basic vector search, an AI-vector database also offers advanced capabilities such as more full-text search, multi-vector retrieval, mixed data type query, refined data analytics, and fused search.</p>
  </details>
<details>
  <summary><b>Where can I find a benchmark report of your database?</b></summary>
 You can find a benchmark report on Infinity, the AI-native database, [here]().
  </details>

## Community

- [Slack](https://join.slack.com/t/infiniflowai/shared_invite/zt-28bstxmrq-WBW7_oyDqct~s8gnYe_6ug)
- [Discord](https://discord.gg/6Zex37FE)
- [Twitter](https://twitter.com/infiniflowai)
- [GitHub Discussions](https://github.com/infiniflow/infinity/discussions)
- WeChat?

<br />

## Contributing

To find out how to make a contribution to Infinity, see the [contribution guidelines](CONTRIBUTING.md).
